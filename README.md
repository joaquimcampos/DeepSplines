<img src="https://github.com/joaquimcampos/DeepSplines/blob/master/img/deepspline_basis.svg" width=50% height=50%>

# Deep Spline Neural Networks

DeepSplines is a framework to train the activation functions of a neural network.

The aim of this repository is to:

-   Facilitate the reproduction of the results reported in the research papers
       -   [Learning Activation Functions in Deep (Spline) Neural Networks](http://bigwww.epfl.ch/publications/bohra2003.html) [[1]](#1)   
       -   [Deep Neural Networks with Trainable Activations and Controlled Lipschitz Constant](http://bigwww.epfl.ch/publications/aziznejad2001.html) [[2]](#2)
-   Enable a seamless integration of Deep Spline activation functions in
    a custom neural network.


The proposed scheme is based on the theoretical work of
[M. Unser](http://bigwww.epfl.ch/publications/unser1901.html) [[3]](#3).


## References
<a id="1">[1]</a>
P. Bohra, J. Campos, H. Gupta, S. Aziznejad, M. Unser,
"Learning Activation Functions in Deep (Spline) Neural Networks,"
IEEE Open Journal of Signal Processing, vol. 1, pp.295-309, November 19, 2020.

<a id="2">[2]</a>
S. Aziznejad, H. Gupta, J. Campos, M. Unser,
"Deep Neural Networks with Trainable Activations and Controlled Lipschitz Constant,"
IEEE Transactions on Signal Processing, vol. 68, pp. 4688-4699, August 10, 2020.

<a id="3">[3]</a>
M. Unser,
"A Representer Theorem for Deep Neural Networks,"
Journal of Machine Learning Research, vol. 20, no. 110, pp. 1-30, January 2019-Present.
